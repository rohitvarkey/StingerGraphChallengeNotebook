{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition SBM Baseline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the Python script by\\n\\nAuthors: Steven Smith, Edward Kao\\nDate: 9 January 2017\\nInstallation: Python 2.7\\n\\nDescription: This Python script performs the baseline graph partition algorithm based on the degree-corrected stochastic block model.\\n\\nReferences:\\nPeixoto, Tiago P. \\\"Entropy of stochastic blockmodel ensembles.\\\" Physical Review E 85, no. 5 (2012): 056122.\\nPeixoto, Tiago P. \\\"Parsimonious module inference in large networks.\\\" Physical review letters 110, no. 14 (2013): 148701.\\nKarrer, Brian, and Mark EJ Newman. \\\"Stochastic blockmodels and community structure in networks.\\\" Physical Review E 83, no. 1 (2011): 016107.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# License\n",
    "\n",
    "#\n",
    "# Copyright 2017 MIT Lincoln Laboratory, Massachusetts Institute of Technology\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use these files except in compliance with\n",
    "# the License.\n",
    "#\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
    "# an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
    "# specific language governing permissions and limitations under the License.\n",
    "#\n",
    "\n",
    "\"\"\"\n",
    "Based on the Python script by\n",
    "\n",
    "Authors: Steven Smith, Edward Kao\n",
    "Date: 9 January 2017\n",
    "Installation: Python 2.7\n",
    "\n",
    "Description: This Python script performs the baseline graph partition algorithm based on the degree-corrected stochastic block model.\n",
    "\n",
    "References:\n",
    "Peixoto, Tiago P. \"Entropy of stochastic blockmodel ensembles.\" Physical Review E 85, no. 5 (2012): 056122.\n",
    "Peixoto, Tiago P. \"Parsimonious module inference in large networks.\" Physical review letters 110, no. 14 (2013): 148701.\n",
    "Karrer, Brian, and Mark EJ Newman. \"Stochastic blockmodels and community structure in networks.\" Physical Review E 83, no. 1 (2011): 016107.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /Users/rohitvarkey/.julia/lib/v0.6/Distributions.ji for module Distributions.\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "using LightGraphs\n",
    "import StatsBase: pweights, sample\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Graph\n",
    "\n",
    "We load the graph into a LightGraphs graph. We do this by reading the edges to be added and adding them onto the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/streaming/emergingEdges/\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const INPUT_PATH = \"data/streaming/emergingEdges/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'load_graph! :: Union{Tuple{LightGraphs.SimpleGraphs.SimpleDiGraph,String,Int64}, Tuple{LightGraphs.SimpleGraphs.SimpleDiGraph,String}}' in module 'Main'.\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "load_graph!"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load graph given the base filename and the number of the streaming peice to be added onto a given graph.\n",
    "\"\"\"\n",
    "function load_graph!(g::DiGraph, filename::String, streaming_num::Int64=1)\n",
    "    info(\"Loading $(filename)_$(streaming_num).tsv\")\n",
    "    edgePieces = readdlm(\"$(filename)_$(streaming_num).tsv\")\n",
    "    for i = 1:size(edgePieces, 1)\n",
    "        # TODO: Add weights also\n",
    "        success = add_edge!(g, edgePieces[i, 1], edgePieces[i, 2])\n",
    "        if success == false\n",
    "            throw(\"Error adding edges.\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the edge counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'initalize_edge_counts :: Tuple{LightGraphs.SimpleGraphs.SimpleDiGraph,Int64,Array{Int64,1}}' in module 'Main'.\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "initalize_edge_counts"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initializes the edge count matrix M between the blocks. \n",
    "Calculates the new out, in and total degrees for the updated edge count matrix.\n",
    "Returns a tuple of M, d_out, d_in, d\n",
    "\"\"\"\n",
    "function initalize_edge_counts(g::DiGraph, B::Int64, b::Vector{Int64})\n",
    "    M = zeros(Int64, B, B) # create a zero matrix of B x B \n",
    "    for v in 1:nv(g)\n",
    "        for n in out_neighbors(g, v)\n",
    "            # Increment count by 1\n",
    "            # NOTE: Column major instead of row major\n",
    "            info(\"Incrementing M at ($(b[n]), $(b[v]) )\")\n",
    "            M[b[n], b[v]] += 1\n",
    "        end\n",
    "    end\n",
    "    # Sum across rows to get the outdegrees for each block\n",
    "    d_out = reshape(sum(M, 1), B)\n",
    "    # Sum across cols to get the indegrees for each block\n",
    "    d_in = reshape(sum(M, 2), B)\n",
    "    d = d_out + d_in\n",
    "    return M, d_out, d_in, d\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose a new block assignment for the current node or block\n",
    "\n",
    "### Parameters\n",
    "    r : Int64\n",
    "            current block assignment for the node under consideration\n",
    "    neighbors_out : Array{Int64, 2}, has 2 columns.\n",
    "            out neighbors for the block\n",
    "    neighbors_in : Array{Int64, 2}, has 2 columns.\n",
    "            in neighbors for the block\n",
    "    b : Vector{Int64}\n",
    "        array of block assignment for each node\n",
    "    M : Array{Int64, 2}, size is (B, B)\n",
    "            edge count matrix between all the blocks.\n",
    "    d : Vector{Int}\n",
    "            total number of edges to and from each block\n",
    "    B : Int64\n",
    "            total number of blocks\n",
    "    agg_move : Bool\n",
    "            whether the proposal is a block move\n",
    "\n",
    "### Returns\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    k_out : int\n",
    "            the out degree of the node\n",
    "    k_in : int\n",
    "            the in degree of the node\n",
    "    k : int\n",
    "            the total degree of the node\n",
    "\n",
    "### Notes\n",
    "- $d_u$: degree of block u\n",
    "\n",
    "Randomly select a neighbor of the current node, and obtain its block assignment $u$. With probability $\\frac{B}{d_u + B}$, randomly propose\n",
    "a block. Otherwise, randomly selects a neighbor to block $u$ and propose its block assignment. For block (agglomerative) moves,\n",
    "avoid proposing the current block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "propose_new_partition (generic function with 1 method)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function propose_new_partition(\n",
    "        r::Int64, neighbors_out::Array{Int64, 2}, neighbors_in::Array{Int64, 2}, b::Vector{Int64}, M::Array{Int64, 2},\n",
    "        d::Vector{Int64}, B::Int64, agg_move::Bool\n",
    "    )\n",
    "    neighbors = vcat(neighbors_out, neighbors_in)\n",
    "    k_out = sum(neighbors_out[:, 1])\n",
    "    k_in = sum(neighbors_in[:, 1])\n",
    "    k = k_out + k_in\n",
    "    rand_neighbor = sample(neighbors[:,0], pweights(neighbors[:,1]/k))\n",
    "    u = b[rand_neighbor]\n",
    "    # propose a new block randomly\n",
    "    if rand() <= B/(d[u] + B)  # chance inversely prop. to block_degree\n",
    "        if agg_move  # force proposal to be different from current block\n",
    "            candidates = set(1:B)\n",
    "            pop!(candidates, r)\n",
    "            s = sample(collect(candidates))\n",
    "        else\n",
    "            s = rand(1:B)\n",
    "        end\n",
    "    else  # propose by random draw from neighbors of block partition[rand_neighbor]\n",
    "        multinomial_prob = M[:, u] + M[u, :] / d[u]\n",
    "        if agg_move  # force proposal to be different from current block\n",
    "            multinomial_prob[r] = 0\n",
    "            if sum(multinomial_prob) == 0  # the current block has no neighbors. randomly propose a different block\n",
    "                candidates = set(1:B)\n",
    "                pop!(candidates, r)\n",
    "                s = sample(collect(candidates))\n",
    "                return s, k_out, k_in, k\n",
    "            else\n",
    "                multinomial_prob = multinomial_prob / sum(multinomial_prob)\n",
    "            end\n",
    "        candidates_vec =  findn(multinomial_prob)\n",
    "        s = candidates_vec[findn(rand(Multinomial(1, multinomial_prob[candidates_vec])))[1]]\n",
    "        end\n",
    "    end\n",
    "    return s, k_out, k_in, k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the two new rows and cols of the edge count matrix under the proposal for the current node or block\n",
    "\n",
    "### Parameters\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks.\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    b_out : ndarray (int)\n",
    "            blocks of the out neighbors\n",
    "    count_out : ndarray (int)\n",
    "            edge counts to the out neighbor blocks\n",
    "    b_in : ndarray (int)\n",
    "            blocks of the in neighbors\n",
    "    count_in : ndarray (int)\n",
    "            edge counts to the in neighbor blocks\n",
    "    count_self : int\n",
    "            edge counts to self\n",
    "    agg_move : bool\n",
    "            whether the proposal is a block move\n",
    "    use_sparse : bool\n",
    "            whether the edge count matrix is stored as a sparse matrix\n",
    "\n",
    "### Returns\n",
    "    M_r_row : ndarray or sparse matrix (int)\n",
    "            the current block row of the new edge count matrix under proposal\n",
    "    M_s_row : ndarray or sparse matrix (int)\n",
    "            the proposed block row of the new edge count matrix under proposal\n",
    "    M_r_col : ndarray or sparse matrix (int)\n",
    "            the current block col of the new edge count matrix under proposal\n",
    "    M_s_col : ndarray or sparse matrix (int)\n",
    "            the proposed block col of the new edge count matrix under proposal\n",
    "\n",
    "### Notes\n",
    "The updates only involve changing the entries to and from the neighboring blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_new_rows_cols_interblock_edge_count_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_new_rows_cols_interblock_edge_count_matrix(\n",
    "        M::Array{Int64, 2}, r::Int64, s::Int64, b_out::Vector{Int64}, count_out::Vector{Int64}, \n",
    "        b_in::Vector{Int64}, count_in::Vector{Int64}, count_self::Int64, agg_move::Bool)\n",
    "    B = size(M, 1)\n",
    "    M_r_row = zeros(B)\n",
    "    M_r_col = zeros(B)\n",
    "    if agg_move == false\n",
    "        M_r_row = M[r, :]\n",
    "        M_r_col = M[:, r]\n",
    "        \n",
    "        M_r_col[b_out] -= count_out\n",
    "        M_r_col[r] -= sum(count_in[find(x->x==r, b_in)])\n",
    "        M_r_col[s] += sum(count_in[find(x->x==r, b_in)])\n",
    "        \n",
    "        M_r_row[b_in] -= count_in\n",
    "        M_r_row[r] -= sum(count_out[find(x->x==r, b_out)])\n",
    "        M_r_row[s] += sum(count_out[find(x->x==r, b_out)])\n",
    "    end\n",
    "    M_s_row = M[s, :]\n",
    "    M_s_col = M[:, s]\n",
    "    \n",
    "    M_s_col[b_out] += count_out\n",
    "    M_s_col[r] -= count_self\n",
    "    M_s_col[s] += count_self\n",
    "    M_s_col[r] -= sum(count_in[find(x->x==s, b_in)])\n",
    "    M_s_col[s] += sum(count_in[find(x->x==s, b_in)])\n",
    "    \n",
    "    M_s_row[b_in] += count_in\n",
    "    M_s_row[r] -= sum(count_out[find(x->x==s, b_out)])\n",
    "    M_s_row[s] += sum(count_out[find(x->x==s, b_out)])\n",
    "    M_s_row[r] -= count_self\n",
    "    M_s_row[s] += count_self\n",
    "    \n",
    "    return M_r_row, M_s_row, M_r_col, M_s_col\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the new block degrees under the proposal for the current node or block\n",
    "\n",
    "### Parameters\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    d_out : ndarray (int)\n",
    "            the current out degree of each block\n",
    "    d_in : ndarray (int)\n",
    "            the current in degree of each block\n",
    "    d : ndarray (int)\n",
    "            the current total degree of each block\n",
    "    k_out : int\n",
    "            the out degree of the node\n",
    "    k_in : int\n",
    "            the in degree of the node\n",
    "    k : int\n",
    "            the total degree of the node\n",
    "\n",
    "### Returns\n",
    "    d_out_new : ndarray (int)\n",
    "            the new out degree of each block under proposal\n",
    "    d_in_new : ndarray (int)\n",
    "            the new in degree of each block under proposal\n",
    "    d_new : ndarray (int)\n",
    "            the new total degree of each block under proposal\n",
    "\n",
    "### Notes\n",
    "The updates only involve changing the degrees of the current and proposed block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_new_block_degrees (generic function with 1 method)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_new_block_degrees(\n",
    "        r::Int64, s::Int64, d_out::Vector{Int64}, d_in::Vector{Int64}, d::Vector{Int64}, \n",
    "        k_out::Int64, k_in::Int64, k::Int64\n",
    "    )\n",
    "    new_degrees = [copy(degrees) for degrees in [d_out, d_in, d]]\n",
    "    for (new_d, degree) in zip(new_degrees, [k_out, k_in, k])\n",
    "        new_d[r] -= degree\n",
    "        new_d[s] += degree\n",
    "    end\n",
    "    return new_degrees\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute change in entropy under the proposal\n",
    "Reduction in entropy means the proposed block is better than the current block.\n",
    "\n",
    "### Parameters\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks.\n",
    "    M_r_row : ndarray or sparse matrix (int)\n",
    "            the current block row of the new edge count matrix under proposal\n",
    "    M_s_row : ndarray or sparse matrix (int)\n",
    "            the proposed block row of the new edge count matrix under proposal\n",
    "    M_r_col : ndarray or sparse matrix (int)\n",
    "            the current block col of the new edge count matrix under proposal\n",
    "    M_s_col : ndarray or sparse matrix (int)\n",
    "            the proposed block col of the new edge count matrix under proposal\n",
    "    d_out : ndarray (int)\n",
    "            the current out degree of each block\n",
    "    d_in : ndarray (int)\n",
    "            the current in degree of each block\n",
    "    d_out_new : ndarray (int)\n",
    "            the new out degree of each block under proposal\n",
    "    d_in_new : ndarray (int)\n",
    "            the new in degree of each block under proposal\n",
    "    use_sparse : bool\n",
    "            whether the edge count matrix is stored as a sparse matrix\n",
    "\n",
    "### Returns\n",
    "    delta_entropy : float\n",
    "            entropy under the proposal minus the current entropy\n",
    "\n",
    "### Notes\n",
    "- $M^-$: current edge count matrix between the blocks\n",
    "- $M^+$: new edge count matrix under the proposal\n",
    "- $d^-_{t, \\rm in}$: current in degree of block $t$\n",
    "- $d^-_{t, \\rm out}$: current out degree of block $t$\n",
    "- $d^+_{t, \\rm in}$: new in degree of block $t$ under the proposal\n",
    "- $d^+_{t, \\rm out}$: new out degree of block $t$ under the proposal\n",
    "\n",
    "The difference in entropy is computed as:\n",
    "\n",
    "$\\large \\Delta S = \\sum_{t_1, t_2} {\\left[ -M_{t_1 t_2}^+ \\log\\left(\\frac{M_{t_1 t_2}^+}{d_{t_1, \\rm out}^+ d_{t_2, \\rm in}^+}\\right) + M_{t_1 t_2}^- \\log\\left(\\frac{M_{t_1 t_2}^-}{d_{t_1, \\rm out}^- d_{t_2, \\rm in}^-}\\right)\\right]}$\n",
    "\n",
    "where the sum runs over all entries $(t_1, t_2)$ in rows and cols $r$ and $s$ of the edge count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_delta_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_delta_entropy(\n",
    "        r::Int64, s::Int64, M::Array{Int64, 2}, M_r_row::Vector{Int64}, M_s_row::Vector{Int64}, M_r_col::Vector{Int64},\n",
    "        M_s_col::Vector{Int64}, d_out::Vector{Int64}, d_in::Vector{Int64}, d_out_new::Vector{Int64}, \n",
    "        d_in_new::Vector{Int64}\n",
    "    )\n",
    "    \n",
    "    #TODO: Test!\n",
    "    M_r_t1 = M[:, r]\n",
    "    M_s_t1 = M[:, s]\n",
    "    M_t2_r = M[r, :]\n",
    "    M_t2_s = M[s, :]\n",
    "\n",
    "    # remove r and s from the cols to avoid double counting\n",
    "    idx = filter(x-> x∉[r,s], 1:length(d_in_new))\n",
    "    \n",
    "    M_r_col = M_r_col[idx]\n",
    "    M_s_col = M_s_col[idx]\n",
    "    \n",
    "    M_t2_r = M_t2_r[idx]\n",
    "    M_t2_s = M_t2_s[idx]\n",
    "    \n",
    "    d_out_new_ = d_out_new[idx]\n",
    "    d_out_ = d_out[idx]\n",
    "\n",
    "    # only keep non-zero entries to avoid unnecessary computation\n",
    "    d_in_new_r_row = d_in_new[findn(M_r_row)]\n",
    "    d_in_new_s_row = d_in_new[findn(M_s_row)]\n",
    "    M_r_row = M_r_row[findn(M_r_row)]\n",
    "    M_s_row = M_s_row[findn(M_s_row)]\n",
    "    d_out_new_r_col = d_out_new_[findn(M_r_col)]\n",
    "    d_out_new_s_col = d_out_new_[findn(M_s_col)]\n",
    "    M_r_col = M_r_col[findn(M_r_col)]\n",
    "    M_s_col = M_s_col[findn(M_s_col)]\n",
    "    d_in_r_t1 = d_in[findn(M_r_t1)]\n",
    "    d_in_s_t1 = d_in[findn(M_s_t1)]\n",
    "    M_r_t1= M_r_t1[findn(M_r_t1)]\n",
    "    M_s_t1 = M_s_t1[findn(M_s_t1)]\n",
    "    d_out_r_col = d_out_[findn(M_t2_r)]\n",
    "    d_out_s_col = d_out_[findn(M_t2_s)]\n",
    "    M_t2_r = M_t2_r[findn(M_t2_r)]\n",
    "    M_t2_s = M_t2_s[findn(M_t2_s)]\n",
    "\n",
    "    # sum over the two changed rows and cols\n",
    "    delta_entropy = 0\n",
    "    delta_entropy -= sum(M_r_row * np.log(M_r_row / d_in_new_r_row / d_out_new[r]))\n",
    "    delta_entropy -= sum(M_s_row * np.log(M_s_row / d_in_new_s_row / d_out_new[s]))\n",
    "    delta_entropy -= sum(M_r_col * np.log(M_r_col / d_out_new_r_col / d_in_new[r]))\n",
    "    delta_entropy -= sum(M_s_col * np.log(M_s_col / d_out_new_s_col / d_in_new[s]))\n",
    "    delta_entropy += sum(M_r_t1 * np.log(M_r_t1 / d_in_r_t1 / d_out[r]))\n",
    "    delta_entropy += sum(M_s_t1 * np.log(M_s_t1 / d_in_s_t1 / d_out[s]))\n",
    "    delta_entropy += sum(M_t2_r * np.log(M_t2_r / d_out_r_col / d_in[r]))\n",
    "    delta_entropy += sum(M_t2_s * np.log(M_t2_s / d_out_s_col / d_in[s]))\n",
    "    return delta_entropy\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the best merge (agglomerative) moves to reduce a set number of blocks\n",
    "\n",
    "### Parameters\n",
    "    delta_entropy_for_each_block : ndarray (float)\n",
    "            the delta entropy for merging each block\n",
    "    best_merge_for_each_block : ndarray (int)\n",
    "            the best block to merge with for each block\n",
    "    b : ndarray (int)\n",
    "            array of block assignment for each node\n",
    "    B : int\n",
    "            total number of blocks in the current partition\n",
    "    B_to_merge : int\n",
    "            the number of blocks to merge\n",
    "\n",
    "### Returns\n",
    "    b : ndarray (int)\n",
    "            array of new block assignment for each node after the merge\n",
    "    B : int\n",
    "            total number of blocks after the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function carry_out_best_merges(\n",
    "        delta_entropy_for_each_block::Vector{Int64}, best_merge_for_each_block::Vector{Int64}, \n",
    "        b::Vector{Int64}, B::Int64, B_to_merge::Int64\n",
    "    )\n",
    "    bestMerges = delta_entropy_for_each_block.argsort()\n",
    "    block_map = 1:B\n",
    "    num_merge = 0\n",
    "    counter = 0\n",
    "    while num_merge < B_to_merge:\n",
    "        mergeFrom = bestMerges[counter]\n",
    "        mergeTo = block_map[best_merge_for_each_block[bestMerges[counter]]]\n",
    "        counter += 1\n",
    "        if mergeTo != mergeFrom:\n",
    "            block_map[np.where(block_map == mergeFrom)] = mergeTo\n",
    "            b[np.where(b == mergeFrom)] = mergeTo\n",
    "            num_merge += 1\n",
    "    remaining_blocks = np.unique(b)\n",
    "    mapping = -np.ones(B, dtype=int)\n",
    "    mapping[remaining_blocks] = np.arange(len(remaining_blocks))\n",
    "    b = mapping[b]\n",
    "    B -= B_to_merge\n",
    "    return b, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91msyntax: line break in \":\" expression\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91msyntax: line break in \":\" expression\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "function main(num_vertices::Int64, base_filename::String)\n",
    "    #input_filename = '../../data/static/simulated_blockmodel_graph_500_nodes'\n",
    "    #true_partition_available = true\n",
    "    #visualize_graph = True # whether to plot the graph layout colored with intermediate partitions\n",
    "    #verbose = True # whether to print updates of the partitioning\n",
    "    \n",
    "    # Create the graph\n",
    "    g = DiGraph(num_vertices)\n",
    "    # Load the first part of the graph\n",
    "    load_graph!(g, base_filename, 1)\n",
    "    info(g, \"Loaded\")\n",
    "\n",
    "    # initialize by putting each node in its own block (N blocks)\n",
    "    num_blocks = num_vertices\n",
    "    partition = collect(1:num_vertices)\n",
    "\n",
    "    # partition update parameters\n",
    "    β = 3 # exploitation versus exploration (higher value favors exploitation)\n",
    "\n",
    "    # agglomerative partition update parameters\n",
    "    num_agg_proposals_per_block = 10 # number of proposals per block\n",
    "    num_block_reduction_rate = 0.5 # fraction of blocks to reduce until the golden ratio bracket is established\n",
    "\n",
    "    # nodal partition updates parameters\n",
    "    max_num_nodal_itr = 100 # maximum number of iterations\n",
    "    delta_entropy_threshold1 = 5e-4 # stop iterating when the change in entropy falls below this fraction of the overall entropy\n",
    "                                    # lowering this threshold results in more nodal update iterations and likely better performance, but longer runtime\n",
    "    delta_entropy_threshold2 = 1e-4 # threshold after the golden ratio bracket is established (typically lower to fine-tune to partition) \n",
    "    delta_entropy_moving_avg_window = 3 # width of the moving average window for the delta entropy convergence criterion\n",
    "\n",
    "    # initialize edge counts and block degrees\n",
    "    interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees = \\\n",
    "        initialize_edge_counts(g, num_blocks, partition)\n",
    "\n",
    "    # initialize items before iterations to find the partition with the optimal number of blocks\n",
    "    optimal_B_found = false\n",
    "    old_b = [[], [], []]  # partition for the high, best, and low number of blocks so far\n",
    "    old_M = [[], [], []]  # edge count matrix for the high, best, and low number of blocks so far\n",
    "    old_d = [[], [], []]  # block degrees for the high, best, and low number of blocks so far\n",
    "    old_d_out = [[], [], []]  # out block degrees for the high, best, and low number of blocks so far\n",
    "    old_d_in = [[], [], []]  # in block degrees for the high, best, and low number of blocks so far\n",
    "    old_S = [Inf, Inf, Inf] # overall entropy for the high, best, and low number of blocks so far\n",
    "    old_B = [[], [], []]  # number of blocks for the high, best, and low number of blocks so far\n",
    "    \n",
    "    \n",
    "    num_blocks_to_merge = floor(Int64, num_blocks*num_block_reduction_rate)\n",
    "\n",
    "    # begin partitioning by finding the best partition with the optimal number of blocks\n",
    "    while optimal_num_blocks_found == false\n",
    "        # begin agglomerative partition updates (i.e. block merging)\n",
    "        println(\"\\nMerging down blocks from $num_blocks to $(num_blocks - num_blocks_to_merge)\")\n",
    "        \n",
    "        best_merge_for_each_block = fill(-1, num_blocks) # initialize to no merge\n",
    "        delta_entropy_for_each_block = fill(Inf, num_blocks) # initialize criterion\n",
    "        block_partition = 1:num_blocks\n",
    "        for current_block in 1:num_blocks # evalaute agglomerative updates for each block\n",
    "            for proposal_idx in 1:num_agg_proposals_per_block\n",
    "                # populate edges to neighboring blocks\n",
    "                out_blocks = findn(interblock_edge_count[:, current_block])\n",
    "                out_blocks_counts = hcat(out_blocks, interblock_edge_count[out_blocks, current_block])\n",
    "                in_blocks = findn(interblock_edge_count[current_block, :])\n",
    "                in_blocks_counts = hcat(in_blocks, interblock_edge_count[current_block, in_blocks])\n",
    "\n",
    "                # propose a new block to merge with\n",
    "                proposal, num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges = \\\n",
    "                    propose_new_partition(\n",
    "                        current_block, out_blocks_counts, in_blocks_counts, block_partition, \n",
    "                        interblock_edge_count, block_degrees, num_blocks, 1\n",
    "                    )\n",
    "\n",
    "                # compute the two new rows and columns of the interblock edge count matrix\n",
    "                new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col = \\\n",
    "                    compute_new_rows_cols_interblock_edge_count_matrix(interblock_edge_count, current_block, proposal, out_blocks[:,0], out_blocks[:,1], in_blocks[:,0], in_blocks[:,1], interblock_edge_count[current_block, current_block], 1)    \n",
    "\n",
    "                # compute new block degrees           \n",
    "                block_degrees_out_new, block_degrees_in_new, block_degrees_new = \\\n",
    "                    compute_new_block_degrees(\n",
    "                        current_block, proposal, block_degrees_out, block_degrees_in, block_degrees, \n",
    "                        num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges\n",
    "                )\n",
    "\n",
    "                # compute change in entropy / posterior\n",
    "                delta_entropy = compute_delta_entropy(current_block, proposal, interblock_edge_count, new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col, block_degrees_out, block_degrees_in, block_degrees_out_new, block_degrees_in_new, use_sparse_matrix)\n",
    "                if delta_entropy < delta_entropy_for_each_block[current_block]: # a better block candidate was found\n",
    "                    best_merge_for_each_block[current_block] = proposal\n",
    "                    delta_entropy_for_each_block[current_block] = delta_entropy\n",
    "\n",
    "        # carry out the best merges\n",
    "        partition, num_blocks = carry_out_best_merges(delta_entropy_for_each_block, best_merge_for_each_block, partition, num_blocks, num_blocks_to_merge)\n",
    "\n",
    "        # re-initialize edge counts and block degrees\n",
    "        interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees = initialize_edge_counts(out_neighbors, num_blocks, partition, use_sparse_matrix)\n",
    "\n",
    "        # perform nodal partition updates\n",
    "        if verbose:\n",
    "            print(\"Beginning nodal updates\")\n",
    "        total_num_nodal_moves = 0            \n",
    "        itr_delta_entropy = np.zeros(max_num_nodal_itr)\n",
    "\n",
    "        # compute the global entropy for MCMC convergence criterion\n",
    "        overall_entropy = compute_overall_entropy(interblock_edge_count, block_degrees_out, block_degrees_in, num_blocks, N, E, use_sparse_matrix)\n",
    "\n",
    "        for itr in range(max_num_nodal_itr):\n",
    "            num_nodal_moves = 0;\n",
    "            itr_delta_entropy[itr] = 0\n",
    "\n",
    "            for current_node in range(N):\n",
    "                current_block = partition[current_node] \n",
    "                # propose a new block for this node\n",
    "                proposal, num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges = propose_new_partition(current_block, out_neighbors[current_node], in_neighbors[current_node], partition, interblock_edge_count, block_degrees, num_blocks, 0, use_sparse_matrix)\n",
    "\n",
    "                # determine whether to accept or reject the proposal\n",
    "                if (proposal != current_block):\n",
    "                    # compute block counts of in and out neighbors\n",
    "                    blocks_out, inverse_idx_out = np.unique(partition[out_neighbors[current_node][:,0]], return_inverse = True)\n",
    "                    count_out = np.bincount(inverse_idx_out, weights=out_neighbors[current_node][:,1]).astype(int)\n",
    "                    blocks_in, inverse_idx_in = np.unique(partition[in_neighbors[current_node][:,0]], return_inverse = True)\n",
    "                    count_in = np.bincount(inverse_idx_in, weights=in_neighbors[current_node][:,1]).astype(int)\n",
    "\n",
    "                    # compute the two new rows and columns of the interblock edge count matrix\n",
    "                    self_edge_weight = np.sum(out_neighbors[current_node][np.where(out_neighbors[current_node][:,0]==current_node),1]) # check if this node has a self edge\n",
    "                    new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col = \\\n",
    "                        compute_new_rows_cols_interblock_edge_count_matrix(interblock_edge_count, current_block, proposal, blocks_out, count_out, blocks_in, count_in, self_edge_weight, 0, use_sparse_matrix)\n",
    "\n",
    "                    # compute new block degrees           \n",
    "                    block_degrees_out_new, block_degrees_in_new, block_degrees_new = compute_new_block_degrees(current_block, proposal, block_degrees_out, block_degrees_in, block_degrees, num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges)\n",
    "\n",
    "                    # compute the Hastings correction\n",
    "                    Hastings_correction = compute_Hastings_correction(blocks_out, count_out, blocks_in, count_in, proposal, interblock_edge_count, new_interblock_edge_count_current_block_row, new_interblock_edge_count_current_block_col, num_blocks, block_degrees, block_degrees_new, use_sparse_matrix)\n",
    "\n",
    "                    # compute change in entropy / posterior\n",
    "                    delta_entropy = compute_delta_entropy(current_block, proposal, interblock_edge_count, new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col, block_degrees_out, block_degrees_in, block_degrees_out_new, block_degrees_in_new, use_sparse_matrix)\n",
    "\n",
    "                    # compute probability of acceptance\n",
    "                    p_accept = np.min([np.exp(-beta*delta_entropy)*Hastings_correction, 1])\n",
    "\n",
    "                    # if accept the proposal, update the partition, inter_block_edge_count, and block degrees\n",
    "                    if (np.random.uniform() <= p_accept):\n",
    "                        total_num_nodal_moves += 1\n",
    "                        num_nodal_moves += 1\n",
    "                        itr_delta_entropy[itr] += delta_entropy\n",
    "                        partition, interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees = update_partition(partition, current_node, current_block, proposal, interblock_edge_count, new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col, block_degrees_out_new, block_degrees_in_new, block_degrees_new, use_sparse_matrix)\n",
    "            if verbose:\n",
    "                print(\"Itr: {}, number of nodal moves: {}, delta S: {:0.5f}\".format(itr, num_nodal_moves, itr_delta_entropy[itr]/float(overall_entropy)))\n",
    "            if itr>=(delta_entropy_moving_avg_window-1): # exit MCMC if the recent change in entropy falls below a small fraction of the overall entropy\n",
    "                if not(np.all(np.isfinite(old_overall_entropy))): # golden ratio bracket not yet established \n",
    "                    if (-np.mean(itr_delta_entropy[(itr-delta_entropy_moving_avg_window+1):itr]) < (delta_entropy_threshold1*overall_entropy)):\n",
    "                        break\n",
    "                else: # golden ratio bracket is established. Fine-tuning partition.\n",
    "                    if (-np.mean(itr_delta_entropy[(itr-delta_entropy_moving_avg_window+1):itr]) < (delta_entropy_threshold2*overall_entropy)):\n",
    "                        break\n",
    "\n",
    "        # compute the global entropy for determining the optimal number of blocks\n",
    "        overall_entropy = compute_overall_entropy(interblock_edge_count, block_degrees_out, block_degrees_in, num_blocks, N, E, use_sparse_matrix)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Total number of nodal moves: {}, overall_entropy: {:0.2f}\".format(total_num_nodal_moves, overall_entropy))\n",
    "        if visualize_graph & use_graph_tool_options:\n",
    "            graph_object = plot_graph_with_partition(out_neighbors, partition, graph_object)\n",
    "\n",
    "        # check whether the partition with optimal number of block has been found; if not, determine and prepare for the next number of blocks to try\n",
    "        partition, interblock_edge_count, block_degrees, block_degrees_out, block_degrees_in, num_blocks, num_blocks_to_merge, old_partition, old_interblock_edge_count, old_block_degrees, old_block_degrees_out, old_block_degrees_in, old_overall_entropy, old_num_blocks, optimal_num_blocks_found = \\\n",
    "            prepare_for_partition_on_next_num_blocks(overall_entropy, partition, interblock_edge_count, block_degrees, block_degrees_out, block_degrees_in, num_blocks, old_partition, old_interblock_edge_count, old_block_degrees, old_block_degrees_out, old_block_degrees_in, old_overall_entropy, old_num_blocks, num_block_reduction_rate)\n",
    "\n",
    "        if verbose:\n",
    "            print('Overall entropy: {}'.format(old_overall_entropy))\n",
    "            print('Number of blocks: {}'.format(old_num_blocks))\n",
    "            if optimal_num_blocks_found:\n",
    "                print('\\nOptimal partition found with {} blocks'.format(num_blocks))\n",
    "    if use_timeit:\n",
    "        t1 = timeit.default_timer()\n",
    "        print('\\nGraph partition took {} seconds'.format(t1-t0))\n",
    "\n",
    "    # evaluate output partition against the true partition\n",
    "    evaluate_partition(true_partition, partition)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: no not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: no not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: np not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: np not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
