{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition SBM Baseline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License\n",
    "\n",
    "#\n",
    "# Copyright 2017 MIT Lincoln Laboratory, Massachusetts Institute of Technology\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use these files except in compliance with\n",
    "# the License.\n",
    "#\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
    "# an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
    "# specific language governing permissions and limitations under the License.\n",
    "#\n",
    "\n",
    "\"\"\"\n",
    "Based on the Python script by\n",
    "\n",
    "Authors: Steven Smith, Edward Kao\n",
    "Date: 9 January 2017\n",
    "Installation: Python 2.7\n",
    "\n",
    "Description: This Python script performs the baseline graph partition algorithm based on the degree-corrected stochastic block model.\n",
    "\n",
    "References:\n",
    "Peixoto, Tiago P. \"Entropy of stochastic blockmodel ensembles.\" Physical Review E 85, no. 5 (2012): 056122.\n",
    "Peixoto, Tiago P. \"Parsimonious module inference in large networks.\" Physical review letters 110, no. 14 (2013): 148701.\n",
    "Karrer, Brian, and Mark EJ Newman. \"Stochastic blockmodels and community structure in networks.\" Physical Review E 83, no. 1 (2011): 016107.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using LightGraphs\n",
    "using SimpleWeightedGraphs\n",
    "import StatsBase: pweights, sample, countmap\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Graph\n",
    "\n",
    "We load the graph into a LightGraphs graph. We do this by reading the edges to be added and adding them onto the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const INPUT_PATH = \"data/streaming/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_graph!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load graph given the base filename and the number of the streaming peice to be added onto a given graph.\n",
    "\"\"\"\n",
    "function load_graph!(g::SimpleWeightedDiGraph, sampling_type::String, num_vertices::Int64, streaming_num::Int64=1)\n",
    "    if sampling_type == \"snowballSampling\"\n",
    "        sample_name = \"snowball\"\n",
    "    else\n",
    "        sample_name = \"edgeSample\"\n",
    "    end\n",
    "    filename = joinpath(\n",
    "            INPUT_PATH, sampling_type, \"$(num_vertices)_nodes\", \n",
    "            \"simulated_blockmodel_graph_$(num_vertices)_nodes_$(sample_name)_$(streaming_num).tsv\")\n",
    "    edgePieces = readdlm(filename)\n",
    "    for i = 1:size(edgePieces, 1)\n",
    "        success = add_edge!(g, edgePieces[i, 1], edgePieces[i, 2], edgePieces[i, 3])\n",
    "        if success == false\n",
    "            throw(\"Error adding edges.\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_load_graph (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Test.@test\n",
    "function test_load_graph(num_nodes::Int64)\n",
    "    g = SimpleWeightedDiGraph(num_nodes)\n",
    "    edges = 0\n",
    "    for chunk_num = 1:9\n",
    "        load_graph!(g, \"snowballSampling\", num_nodes, chunk_num)\n",
    "        @test nv(g) == num_nodes\n",
    "        edges += countlines(joinpath(\n",
    "                INPUT_PATH, \"snowballSampling\", \"$(num_nodes)_nodes\", \n",
    "                \"simulated_blockmodel_graph_$(num_nodes)_nodes_snowball_$(chunk_num).tsv\"))\n",
    "        @test ne(g) == edges\n",
    "    end\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNote: adding edges to this graph type is not performant.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "test_load_graph(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the edge counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_edge_counts"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initializes the edge count matrix M between the blocks. \n",
    "Calculates the new out, in and total degrees for the updated edge count matrix.\n",
    "Returns a tuple of M, d_out, d_in, d\n",
    "\"\"\"\n",
    "function initialize_edge_counts(g::SimpleWeightedDiGraph, B::Int64, b::Vector{Int64})\n",
    "    M = zeros(Int64, B, B) # create a zero matrix of B x B \n",
    "    for edge in edges(g)\n",
    "            M[b[dst(edge)], b[src(edge)]] += weight(edge)\n",
    "    end\n",
    "    # Sum across rows to get the outdegrees for each block\n",
    "    d_out = reshape(sum(M, 1), B)\n",
    "    # Sum across cols to get the indegrees for each block\n",
    "    d_in = reshape(sum(M, 2), B)\n",
    "    d = d_out + d_in\n",
    "    return M, d_out, d_in, d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_initialize_counts (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_initialize_counts(num_nodes::Int64)\n",
    "    g = SimpleWeightedDiGraph(num_nodes)\n",
    "    load_graph!(g, \"snowballSampling\", num_nodes, 1)\n",
    "    M, d_out, d_in = initialize_edge_counts(g, num_nodes, collect(1:num_nodes))\n",
    "    for edge in edges(g)\n",
    "        @test M[dst(edge), src(edge)] == 1\n",
    "    end\n",
    "    for v in vertices(g)\n",
    "        @test outdegree(g, v) == d_out[v]\n",
    "        @test indegree(g, v) == d_in[v]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_initialize_counts(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose a new block assignment for the current node or block\n",
    "\n",
    "### Parameters\n",
    "    r : Int64\n",
    "            current block assignment for the node under consideration\n",
    "    neighbors_out : Array{Int64, 2}, has 2 columns.\n",
    "            out neighbors for the block\n",
    "    neighbors_in : Array{Int64, 2}, has 2 columns.\n",
    "            in neighbors for the block\n",
    "    b : Vector{Int64}\n",
    "        array of block assignment for each node\n",
    "    M : Array{Int64, 2}, size is (B, B)\n",
    "            edge count matrix between all the blocks.\n",
    "    d : Vector{Int}\n",
    "            total number of edges to and from each block\n",
    "    B : Int64\n",
    "            total number of blocks\n",
    "    agg_move : Bool\n",
    "            whether the proposal is a block move\n",
    "\n",
    "### Returns\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    k_out : int\n",
    "            the out degree of the node\n",
    "    k_in : int\n",
    "            the in degree of the node\n",
    "    k : int\n",
    "            the total degree of the node\n",
    "\n",
    "### Notes\n",
    "- $d_u$: degree of block u\n",
    "\n",
    "Randomly select a neighbor of the current node, and obtain its block assignment $u$. With probability $\\frac{B}{d_u + B}$, randomly propose\n",
    "a block. Otherwise, randomly selects a neighbor to block $u$ and propose its block assignment. For block (agglomerative) moves,\n",
    "avoid proposing the current block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "propose_new_partition (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function propose_new_partition(\n",
    "        r::Int64, neighbors_out::Array{Int64, 2}, neighbors_in::Array{Int64, 2}, b::Vector{Int64}, M::Array{Int64, 2},\n",
    "        d::Vector{Int64}, B::Int64, agg_move::Bool\n",
    "    )\n",
    "    neighbors = vcat(neighbors_out, neighbors_in)\n",
    "    k_out = sum(neighbors_out[:, 2])\n",
    "    k_in = sum(neighbors_in[:, 2])\n",
    "    k = k_out + k_in\n",
    "    rand_neighbor = sample(neighbors[:, 1], pweights(neighbors[:,2]/k))\n",
    "    u = b[rand_neighbor]\n",
    "    # propose a new block randomly\n",
    "    prob = B/(d[u] + B)\n",
    "    #@show B, d[u], prob\n",
    "    random_drawn = rand()\n",
    "    if random_drawn <= prob  # chance inversely prop. to block_degree\n",
    "        #println(\"Picking new block randomly\")\n",
    "        if agg_move  # force proposal to be different from current block\n",
    "            candidates = Set(1:B)\n",
    "            pop!(candidates, r)\n",
    "            s = sample(collect(candidates))\n",
    "        else\n",
    "            s = rand(1:B)\n",
    "        end\n",
    "    else  # propose by random draw from neighbors of block partition[rand_neighbor]\n",
    "        #println(\"random draw from neighbors of block partition[$(rand_neighbor)]\")\n",
    "        multinomial_prob = (M[:, u] + M[u, :]) / d[u]\n",
    "        if agg_move  # force proposal to be different from current block\n",
    "            multinomial_prob[r] = 0\n",
    "            if sum(multinomial_prob) == 0  # the current block has no neighbors. randomly propose a different block\n",
    "                candidates = Set(1:B)\n",
    "                pop!(candidates, r)\n",
    "                s = sample(collect(candidates))\n",
    "                return s, k_out, k_in, k\n",
    "            else\n",
    "                multinomial_prob = multinomial_prob / sum(multinomial_prob)\n",
    "            end\n",
    "        end\n",
    "        if (Distributions.isprobvec(multinomial_prob) == false)\n",
    "            @show multinomial_prob[findn(multinomial_prob)], sum(multinomial_prob)\n",
    "            @show M[:, u][findn(M[:, u])], M[u, :][findn(M[u, :])]\n",
    "            @show ((M[:, u] + M[u, :]) / d[u])[findn((M[:, u] + M[:, u]) / d[u])]\n",
    "            @show d[u]\n",
    "            @show sum(M[:, u][findn(M[:, u])]) + sum(M[u, :][findn(M[u, :])])\n",
    "        end\n",
    "        #multinomial_prob = multinomial_prob / sum(multinomial_prob)\n",
    "        candidates_vec =  findn(multinomial_prob)\n",
    "        s = candidates_vec[findn(rand(Multinomial(1, multinomial_prob[candidates_vec])))[1]]\n",
    "    end\n",
    "    return s, k_out, k_in, k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the two new rows and cols of the edge count matrix under the proposal for the current node or block\n",
    "\n",
    "### Parameters\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks.\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    b_out : ndarray (int)\n",
    "            blocks of the out neighbors\n",
    "    count_out : ndarray (int)\n",
    "            edge counts to the out neighbor blocks\n",
    "    b_in : ndarray (int)\n",
    "            blocks of the in neighbors\n",
    "    count_in : ndarray (int)\n",
    "            edge counts to the in neighbor blocks\n",
    "    count_self : int\n",
    "            edge counts to self\n",
    "    agg_move : bool\n",
    "            whether the proposal is a block move\n",
    "    use_sparse : bool\n",
    "            whether the edge count matrix is stored as a sparse matrix\n",
    "\n",
    "### Returns\n",
    "    M_r_row : ndarray or sparse matrix (int)\n",
    "            the current block row of the new edge count matrix under proposal\n",
    "    M_s_row : ndarray or sparse matrix (int)\n",
    "            the proposed block row of the new edge count matrix under proposal\n",
    "    M_r_col : ndarray or sparse matrix (int)\n",
    "            the current block col of the new edge count matrix under proposal\n",
    "    M_s_col : ndarray or sparse matrix (int)\n",
    "            the proposed block col of the new edge count matrix under proposal\n",
    "\n",
    "### Notes\n",
    "The updates only involve changing the entries to and from the neighboring blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_new_rows_cols_interblock_edge_count_matrix (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_new_rows_cols_interblock_edge_count_matrix(\n",
    "        M::Array{Int64, 2}, r::Int64, s::Int64, b_out::Vector{Int64}, count_out::Vector{Int64}, \n",
    "        b_in::Vector{Int64}, count_in::Vector{Int64}, count_self::Int64, agg_move::Bool)\n",
    "    B = size(M, 1)\n",
    "    if agg_move\n",
    "        M_r_row = zeros(Int64, B)\n",
    "        M_r_col = zeros(Int64, B)\n",
    "    else\n",
    "        M_r_row = copy(M[:, r])\n",
    "        M_r_col = copy(M[r, :])\n",
    "        \n",
    "        M_r_col[b_out] -= count_out\n",
    "        M_r_col[r] -= sum(count_in[findin(b_in, r)])\n",
    "        M_r_col[s] += sum(count_in[findin(b_in, r)])\n",
    "        \n",
    "        M_r_row[b_in] -= count_in\n",
    "        M_r_row[r] -= sum(count_out[findin(b_out, r)])\n",
    "        M_r_row[s] += sum(count_out[findin(b_out, r)])\n",
    "    end\n",
    "    M_s_col = copy(M[s, :])\n",
    "    M_s_row = copy(M[:, s])\n",
    "    \n",
    "    M_s_col[b_out] += count_out\n",
    "    M_s_col[r] -= count_self\n",
    "    M_s_col[s] += count_self\n",
    "    M_s_col[r] -= sum(count_in[findin(b_in, s)])\n",
    "    M_s_col[s] += sum(count_in[findin(b_in, s)])\n",
    "    \n",
    "    M_s_row[b_in] += count_in\n",
    "    M_s_row[r] -= sum(count_out[findin(b_out, r)])\n",
    "    M_s_row[s] += sum(count_out[findin(b_out, r)])\n",
    "    M_s_row[r] -= count_self\n",
    "    M_s_row[s] += count_self\n",
    "    \n",
    "    return M_r_row, M_s_row, M_r_col, M_s_col\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the new block degrees under the proposal for the current node or block\n",
    "\n",
    "### Parameters\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    d_out : ndarray (int)\n",
    "            the current out degree of each block\n",
    "    d_in : ndarray (int)\n",
    "            the current in degree of each block\n",
    "    d : ndarray (int)\n",
    "            the current total degree of each block\n",
    "    k_out : int\n",
    "            the out degree of the node\n",
    "    k_in : int\n",
    "            the in degree of the node\n",
    "    k : int\n",
    "            the total degree of the node\n",
    "\n",
    "### Returns\n",
    "    d_out_new : ndarray (int)\n",
    "            the new out degree of each block under proposal\n",
    "    d_in_new : ndarray (int)\n",
    "            the new in degree of each block under proposal\n",
    "    d_new : ndarray (int)\n",
    "            the new total degree of each block under proposal\n",
    "\n",
    "### Notes\n",
    "The updates only involve changing the degrees of the current and proposed block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_new_block_degrees (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_new_block_degrees(\n",
    "        r::Int64, s::Int64, d_out::Vector{Int64}, d_in::Vector{Int64}, d::Vector{Int64}, \n",
    "        k_out::Int64, k_in::Int64, k::Int64\n",
    "    )\n",
    "    new_degrees = [copy(degrees) for degrees in [d_out, d_in, d]]\n",
    "    for (new_d, degree) in zip(new_degrees, [k_out, k_in, k])\n",
    "        new_d[r] -= degree\n",
    "        new_d[s] += degree\n",
    "    end\n",
    "    return new_degrees\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute change in entropy under the proposal\n",
    "Reduction in entropy means the proposed block is better than the current block.\n",
    "\n",
    "### Parameters\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks.\n",
    "    M_r_row : ndarray or sparse matrix (int)\n",
    "            the current block row of the new edge count matrix under proposal\n",
    "    M_s_row : ndarray or sparse matrix (int)\n",
    "            the proposed block row of the new edge count matrix under proposal\n",
    "    M_r_col : ndarray or sparse matrix (int)\n",
    "            the current block col of the new edge count matrix under proposal\n",
    "    M_s_col : ndarray or sparse matrix (int)\n",
    "            the proposed block col of the new edge count matrix under proposal\n",
    "    d_out : ndarray (int)\n",
    "            the current out degree of each block\n",
    "    d_in : ndarray (int)\n",
    "            the current in degree of each block\n",
    "    d_out_new : ndarray (int)\n",
    "            the new out degree of each block under proposal\n",
    "    d_in_new : ndarray (int)\n",
    "            the new in degree of each block under proposal\n",
    "    use_sparse : bool\n",
    "            whether the edge count matrix is stored as a sparse matrix\n",
    "\n",
    "### Returns\n",
    "    delta_entropy : float\n",
    "            entropy under the proposal minus the current entropy\n",
    "\n",
    "### Notes\n",
    "- $M^-$: current edge count matrix between the blocks\n",
    "- $M^+$: new edge count matrix under the proposal\n",
    "- $d^-_{t, \\rm in}$: current in degree of block $t$\n",
    "- $d^-_{t, \\rm out}$: current out degree of block $t$\n",
    "- $d^+_{t, \\rm in}$: new in degree of block $t$ under the proposal\n",
    "- $d^+_{t, \\rm out}$: new out degree of block $t$ under the proposal\n",
    "\n",
    "The difference in entropy is computed as:\n",
    "\n",
    "$\\large \\Delta S = \\sum_{t_1, t_2} {\\left[ -M_{t_1 t_2}^+ \\log\\left(\\frac{M_{t_1 t_2}^+}{d_{t_1, \\rm in}^+ d_{t_2, \\rm out}^+}\\right) + M_{t_1 t_2}^- \\log\\left(\\frac{M_{t_1 t_2}^-}{d_{t_1, \\rm in}^- d_{t_2, \\rm out}^-}\\right)\\right]}$\n",
    "\n",
    "where the sum runs over all entries $(t_1, t_2)$ in rows and cols $r$ and $s$ of the edge count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_delta_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_delta_entropy(\n",
    "        r::Int64, s::Int64, M::Array{Int64, 2}, \n",
    "        M_r_col::Vector{Int64}, M_s_col::Vector{Int64}, M_r_row::Vector{Int64},\n",
    "        M_s_row::Vector{Int64}, d_out::Vector{Int64}, d_in::Vector{Int64}, d_out_new::Vector{Int64}, \n",
    "        d_in_new::Vector{Int64}\n",
    "    )\n",
    "    delta = 0.0\n",
    "    # Sum over col of r in new M\n",
    "    for t1 in findn(M_r_col)\n",
    "        # Skip if t1 is r or s to prevent double counting\n",
    "        if t1 ∈ (r, s)\n",
    "            continue\n",
    "        end\n",
    "        delta -= M_r_col[t1] * log(M_r_col[t1] / d_in_new[t1] / d_out_new[r])\n",
    "    end\n",
    "    for t1 in findn(M_s_col)\n",
    "        if t1 ∈ (r, s)\n",
    "            continue\n",
    "        end\n",
    "        delta -= M_s_col[t1] * log(M_s_col[t1] / d_in_new[t1] / d_out_new[s])\n",
    "    end\n",
    "    # Sum over row of r in new M\n",
    "    for t2 in findn(M_r_row)\n",
    "        delta -= M_r_row[t2] * log(M_r_row[t2] / d_in_new[r] / d_out_new[t2])\n",
    "    end\n",
    "    # Sum over row of s in new M\n",
    "    for t2 in findn(M_s_row)\n",
    "        delta -= M_s_row[t2] * log(M_s_row[t2] / d_in_new[s] / d_out_new[t2])\n",
    "    end\n",
    "    # Sum over columns in old M\n",
    "    for t2 in (r, s)\n",
    "        for t1 in findn(M[:, t2])\n",
    "            # Skip if t1 is r or s to prevent double counting\n",
    "            if t1 ∈ (r, s)\n",
    "                continue\n",
    "            end\n",
    "            delta += M[t1, t2] * log(M[t1, t2] / d_in[t1] / d_out[t2])\n",
    "        end\n",
    "    end\n",
    "    # Sum over rows in old M\n",
    "    for t1 in (r, s)\n",
    "        for t2 in findn(M[t1, :])\n",
    "            delta += M[t1, t2] * log(M[t1, t2] / d_in[t1] / d_out[t2])\n",
    "        end\n",
    "    end\n",
    "    return delta\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the best merge (agglomerative) moves to reduce a set number of blocks\n",
    "\n",
    "### Parameters\n",
    "    delta_entropy_for_each_block : ndarray (float)\n",
    "            the delta entropy for merging each block\n",
    "    best_merge_for_each_block : ndarray (int)\n",
    "            the best block to merge with for each block\n",
    "    b : ndarray (int)\n",
    "            array of block assignment for each node\n",
    "    B : int\n",
    "            total number of blocks in the current partition\n",
    "    B_to_merge : int\n",
    "            the number of blocks to merge\n",
    "\n",
    "### Returns\n",
    "    b : ndarray (int)\n",
    "            array of new block assignment for each node after the merge\n",
    "    B : int\n",
    "            total number of blocks after the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carry_out_best_merges (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function carry_out_best_merges(\n",
    "        delta_entropy_for_each_block::Vector{Float64}, best_merge_for_each_block::Vector{Int64}, \n",
    "        b::Vector{Int64}, B::Int64, B_to_merge::Int64\n",
    "    )\n",
    "    bestMerges = sortperm(delta_entropy_for_each_block)\n",
    "    block_map = collect(1:B)\n",
    "    num_merge = 0\n",
    "    counter = 1\n",
    "    while num_merge < B_to_merge\n",
    "        mergeFrom = bestMerges[counter]\n",
    "        mergeTo = block_map[best_merge_for_each_block[bestMerges[counter]]]\n",
    "        counter += 1\n",
    "        if mergeTo != mergeFrom\n",
    "            block_map[findin(block_map, mergeFrom)] = mergeTo\n",
    "            b[findin(b, mergeFrom)] = mergeTo\n",
    "            num_merge += 1\n",
    "        end\n",
    "    end\n",
    "    remaining_blocks = unique(b)\n",
    "    mapping = -ones(Int64, B)\n",
    "    mapping[remaining_blocks] = collect(1:length(remaining_blocks))\n",
    "    b = mapping[b]\n",
    "    B -= B_to_merge\n",
    "    return b, B\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Compute the overall entropy for the current partition\n",
    "Compute the overall entropy, including the model entropy as well as the data entropy, on the current partition. The best partition with an optimal number of blocks will minimize this entropy.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "        edge count matrix between all the blocks.\n",
    "        \n",
    "d_out : ndarray (int)\n",
    "        the current out degrees of each block\n",
    "        \n",
    "d_in : ndarray (int)\n",
    "        the current in degrees of each block\n",
    "        \n",
    "B : int\n",
    "        the number of blocks in the partition\n",
    "        \n",
    "N : int\n",
    "        number of nodes in the graph\n",
    "        \n",
    "E : int\n",
    "        number of edges in the graph\n",
    "        \n",
    "\n",
    "### Returns\n",
    "\n",
    "S : float\n",
    "        the overall entropy of the current partition\n",
    "\n",
    "### Notes\n",
    "\n",
    "$M$: current edge count matrix\n",
    "\n",
    "$d_{t, \\rm out}$: current out degree of block $t$\n",
    "\n",
    "$d_{t, \\rm in}$: current in degree of block $t$\n",
    "\n",
    "$N$: number of nodes\n",
    "\n",
    "$E$: number of edges\n",
    "\n",
    "$B$: number of blocks\n",
    "\n",
    "$C$: some constant invariant to the partition\n",
    "\n",
    "The overall entropy of the partition is computed as:\n",
    "\n",
    "$\\large S = E\\;h\\left(\\frac{B^2}{E}\\right) + N \\log(B) - \\sum_{t_1, t_2} {M_{t_1 t_2} \\log\\left(\\frac{M_{t_1 t_2}}{d_{t_1, \\rm in} d_{t_2, \\rm out}}\\right)} + C$\n",
    "\n",
    "where the function $h(x)=(1+x)\\log(1+x) - x\\log(x)$ and the sum runs over all entries $(t_1, t_2)$ in the edge count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_overall_entropy (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_overall_entropy(M::Array{Int64, 2}, d_out::Vector{Int64}, d_in::Vector{Int64}, B::Int64, N::Int64, E::Int64)\n",
    "    rows, cols = findn(M)  # all non-zero entries\n",
    "    summation_term = 0.0\n",
    "    for col in cols\n",
    "        for row in rows\n",
    "            summation_term -= M[row, col] * log(M[row, col]/ d_in[row] / d_out[col])\n",
    "        end\n",
    "    end\n",
    "    model_S_term = B^2 / E\n",
    "    model_S = E * (1 + model_S_term) * log(1 + model_S_term) - model_S_term * log(model_S_term) + N*log(B)\n",
    "    S = model_S + summation_term\n",
    "    return S\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Hastings correction for the proposed block from the current block\n",
    "\n",
    "### Parameters\n",
    "    b_out : ndarray (int)\n",
    "            blocks of the out neighbors\n",
    "    count_out : ndarray (int)\n",
    "            edge counts to the out neighbor blocks\n",
    "    b_in : ndarray (int)\n",
    "            blocks of the in neighbors\n",
    "    count_in : ndarray (int)\n",
    "            edge counts to the in neighbor blocks\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks.\n",
    "    M_r_row : ndarray or sparse matrix (int)\n",
    "            the current block row of the new edge count matrix under proposal\n",
    "    M_r_col : ndarray or sparse matrix (int)\n",
    "            the current block col of the new edge count matrix under proposal\n",
    "    B : int\n",
    "            total number of blocks\n",
    "    d : ndarray (int)\n",
    "            total number of edges to and from each block\n",
    "    d_new : ndarray (int)\n",
    "            new block degrees under the proposal\n",
    "    use_sparse : bool\n",
    "            whether the edge count matrix is stored as a sparse matrix\n",
    "\n",
    "### Returns\n",
    "    Hastings_correction : float\n",
    "            term that corrects for the transition asymmetry between the current block and the proposed block\n",
    "### Notes\n",
    "- $p_{i, s \\rightarrow r}$ : for node $i$, probability of proposing block $r$ if its current block is $s$\n",
    "- $p_{i, r \\rightarrow s}$ : for node $i$, probability of proposing block $s$ if its current block is $r$\n",
    "- $r$ : current block for node $i$\n",
    "- $s$ : proposed block for node $i$\n",
    "- $M^-$: current edge count matrix between the blocks\n",
    "- $M^+$: new edge count matrix under the proposal\n",
    "- $d^-_t$: current degree of block $t$\n",
    "- $d^+_t$: new degree of block $t$ under the proposal\n",
    "- $\\mathbf{b}_{\\mathcal{N}_i}$: the neighboring blocks to node $i$\n",
    "- $k_i$: the degree of node $i$\n",
    "- $k_{i,t}$ : the degree of node $i$ to block $t$ (i.e. number of edges to and from block $t$)\n",
    "- $B$ : the number of blocks\n",
    "\n",
    "The Hastings correction is: \n",
    "\n",
    "$\\huge \\frac{p_{i, s \\rightarrow r}}{p_{i, r \\rightarrow s}}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\Large p_{i, r \\rightarrow s} = \\sum_{t \\in \\{\\mathbf{b}_{\\mathcal{N}_i}^-\\}} \\left[ {\\frac{k_{i,t}}{k_i} \\frac{M_{ts}^- + M_{st}^- + 1}{d^-_t+B}}\\right]$\n",
    "\n",
    "$\\Large p_{i, s \\rightarrow r} = \\sum_{t \\in \\{\\mathbf{b}_{\\mathcal{N}_i}^-\\}} \\left[ {\\frac{k_{i,t}}{k_i} \\frac{M_{tr}^+ + M_{rt}^+ +1}{d_t^++B}}\\right]$\n",
    "\n",
    "summed over all the neighboring blocks $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_Hastings_correction (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_Hastings_correction(\n",
    "        b_out::Vector{Int64}, count_out::Vector{Int64}, b_in::Vector{Int64}, count_in::Vector{Int64}, \n",
    "        s::Int64, M::Array{Int64, 2}, M_r_row::Vector{Int64}, M_r_col::Vector{Int64}, B::Int64, \n",
    "        d::Vector{Int64}, d_new::Vector{Int64}\n",
    "    )\n",
    "    block_degree_map = countmap(vcat(b_out, b_in), Distributions.weights(vcat(count_out, count_in)))\n",
    "    p_forward = 0.0\n",
    "    p_backward = 0.0\n",
    "    for (t, degree) in block_degree_map\n",
    "        p_forward += degree * (M[t, s] + M[s, t] + 1) / (d[t] + B)\n",
    "        p_backward += degree * (M_r_row[t] + M_r_col[t] + 1) / (d_new[t] + B)\n",
    "    end\n",
    "    return p_backward / p_forward\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the current node to the proposed block and update the edge counts\n",
    "\n",
    "### Parameters\n",
    "    b : ndarray (int)\n",
    "            current array of new block assignment for each node\n",
    "    ni : int\n",
    "            current node index\n",
    "    r : int\n",
    "            current block assignment for the node under consideration\n",
    "    s : int\n",
    "            proposed block assignment for the node under consideration\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks.\n",
    "    M_r_row : ndarray or sparse matrix (int)\n",
    "            the current block row of the new edge count matrix under proposal\n",
    "    M_s_row : ndarray or sparse matrix (int)\n",
    "            the proposed block row of the new edge count matrix under proposal\n",
    "    M_r_col : ndarray or sparse matrix (int)\n",
    "            the current block col of the new edge count matrix under proposal\n",
    "    M_s_col : ndarray or sparse matrix (int)\n",
    "            the proposed block col of the new edge count matrix under proposal\n",
    "    d_out_new : ndarray (int)\n",
    "            the new out degree of each block under proposal\n",
    "    d_in_new : ndarray (int)\n",
    "            the new in degree of each block under proposal\n",
    "    d_new : ndarray (int)\n",
    "            the new total degree of each block under proposal\n",
    "    use_sparse : bool\n",
    "            whether the edge count matrix is stored as a sparse matrix\n",
    "### Returns\n",
    "    b : ndarray (int)\n",
    "            array of block assignment for each node after the move\n",
    "    M : ndarray or sparse matrix (int), shape = (#blocks, #blocks)\n",
    "            edge count matrix between all the blocks after the move\n",
    "    d_out_new : ndarray (int)\n",
    "            the out degree of each block after the move\n",
    "    d_in_new : ndarray (int)\n",
    "            the in degree of each block after the move\n",
    "    d_new : ndarray (int)\n",
    "            the total degree of each block after the move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_partition (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_partition(b::Vector{Int64}, ni::Int64, r::Int64, s::Int64, M::Array{Int64, 2}, M_r_row::Vector{Int64}, \n",
    "    M_s_row::Vector{Int64}, M_r_col::Vector{Int64}, M_s_col::Vector{Int64}, d_out_new::Vector{Int64}, \n",
    "    d_in_new::Vector{Int64}, d_new::Vector{Int64})\n",
    "    b[ni] = s\n",
    "    M[r, :] = M_r_row\n",
    "    M[s, :] = M_s_row\n",
    "    M[:, r] = M_r_col\n",
    "    M[:, s] = M_s_col\n",
    "    return b, M, d_out_new, d_in_new, d_new\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main(sampling_type::String, num_vertices::Int64)\n",
    "    #input_filename = '../../data/static/simulated_blockmodel_graph_500_nodes'\n",
    "    #true_partition_available = true\n",
    "    #visualize_graph = True # whether to plot the graph layout colored with intermediate partitions\n",
    "    #verbose = True # whether to print updates of the partitioning\n",
    "    \n",
    "    # Create the graph\n",
    "    g = SimpleWeightedDiGraph(num_vertices)\n",
    "    # Load the first part of the graph\n",
    "    load_graph!(g, sampling_type, num_vertices, 1)\n",
    "    info(g, \"Loaded\")\n",
    "\n",
    "    # initialize by putting each node in its own block (N blocks)\n",
    "    num_blocks = num_vertices\n",
    "    partition = collect(1:num_vertices)\n",
    "\n",
    "    # partition update parameters\n",
    "    β = 3 # exploitation versus exploration (higher value favors exploitation)\n",
    "\n",
    "    # agglomerative partition update parameters\n",
    "    num_agg_proposals_per_block = 10 # number of proposals per block\n",
    "    num_block_reduction_rate = 0.5 # fraction of blocks to reduce until the golden ratio bracket is established\n",
    "\n",
    "    # nodal partition updates parameters\n",
    "    max_num_nodal_itr = 100 # maximum number of iterations\n",
    "    delta_entropy_threshold1 = 5e-4 # stop iterating when the change in entropy falls below this fraction of the overall entropy\n",
    "                                    # lowering this threshold results in more nodal update iterations and likely better performance, but longer runtime\n",
    "    delta_entropy_threshold2 = 1e-4 # threshold after the golden ratio bracket is established (typically lower to fine-tune to partition) \n",
    "    delta_entropy_moving_avg_window = 3 # width of the moving average window for the delta entropy convergence criterion\n",
    "\n",
    "    # initialize edge counts and block degrees\n",
    "    interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees =\n",
    "        initialize_edge_counts(g, num_blocks, partition)\n",
    "\n",
    "    # initialize items before iterations to find the partition with the optimal number of blocks\n",
    "    optimal_B_found = false\n",
    "    old_b = [[], [], []]  # partition for the high, best, and low number of blocks so far\n",
    "    old_M = [[], [], []]  # edge count matrix for the high, best, and low number of blocks so far\n",
    "    old_d = [[], [], []]  # block degrees for the high, best, and low number of blocks so far\n",
    "    old_d_out = [[], [], []]  # out block degrees for the high, best, and low number of blocks so far\n",
    "    old_d_in = [[], [], []]  # in block degrees for the high, best, and low number of blocks so far\n",
    "    old_S = [Inf, Inf, Inf] # overall entropy for the high, best, and low number of blocks so far\n",
    "    old_B = [[], [], []]  # number of blocks for the high, best, and low number of blocks so far\n",
    "    \n",
    "    \n",
    "    num_blocks_to_merge = floor(Int64, num_blocks*num_block_reduction_rate)\n",
    "\n",
    "    # begin partitioning by finding the best partition with the optimal number of blocks\n",
    " #   while optimal_num_blocks_found == false\n",
    "        # begin agglomerative partition updates (i.e. block merging)\n",
    "        println(\"\\nMerging down blocks from $num_blocks to $(num_blocks - num_blocks_to_merge)\")\n",
    "        \n",
    "        best_merge_for_each_block = fill(-1, num_blocks) # initialize to no merge\n",
    "        delta_entropy_for_each_block = fill(Inf, num_blocks) # initialize criterion\n",
    "        block_partition = collect(1:num_blocks)\n",
    "        for current_block in 1:num_blocks # evalaute agglomerative updates for each block\n",
    "            for proposal_idx in 1:num_agg_proposals_per_block\n",
    "                # populate edges to neighboring blocks\n",
    "                out_blocks = findn(interblock_edge_count[:, current_block])\n",
    "                out_blocks_counts = hcat(out_blocks, interblock_edge_count[out_blocks, current_block])\n",
    "                in_blocks = findn(interblock_edge_count[current_block, :])\n",
    "                in_blocks_counts = hcat(in_blocks, interblock_edge_count[current_block, in_blocks])\n",
    "            \n",
    "                if (length(out_blocks) + length(in_blocks) == 0)\n",
    "                    #println(\"No neighbors found for $(current_block). Skipping.\")\n",
    "                    best_merge_for_each_block[current_block] = current_block\n",
    "                    continue\n",
    "                end\n",
    "                # propose a new block to merge with\n",
    "                proposal, num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges =\n",
    "                    propose_new_partition(\n",
    "                        current_block, out_blocks_counts, in_blocks_counts, block_partition, \n",
    "                        interblock_edge_count, block_degrees, num_blocks, true\n",
    "                    )\n",
    "\n",
    "                # compute the two new rows and columns of the interblock edge count matrix\n",
    "                new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col = \n",
    "                    compute_new_rows_cols_interblock_edge_count_matrix(\n",
    "                        interblock_edge_count, current_block, proposal, \n",
    "                        out_blocks_counts[:, 1], out_blocks_counts[:, 2],\n",
    "                        in_blocks_counts[:, 1], in_blocks_counts[:, 2], \n",
    "                        interblock_edge_count[current_block, current_block], \n",
    "                        true\n",
    "                )    \n",
    "                \n",
    "                # compute new block degrees           \n",
    "                block_degrees_out_new, block_degrees_in_new, block_degrees_new = \n",
    "                    compute_new_block_degrees(\n",
    "                        current_block, proposal, block_degrees_out, block_degrees_in, block_degrees, \n",
    "                        num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges\n",
    "                )\n",
    "\n",
    "                # compute change in entropy / posterior\n",
    "                delta_entropy = compute_delta_entropy(\n",
    "                    current_block, proposal, interblock_edge_count, \n",
    "                    new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col,\n",
    "                    new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row,\n",
    "                    block_degrees_out, block_degrees_in, block_degrees_out_new, block_degrees_in_new\n",
    "                )\n",
    "                \n",
    "                #@show current_block, proposal, delta_entropy\n",
    "                if delta_entropy < delta_entropy_for_each_block[current_block] # a better block candidate was found\n",
    "                    best_merge_for_each_block[current_block] = proposal\n",
    "                    delta_entropy_for_each_block[current_block] = delta_entropy\n",
    "                end\n",
    "            end\n",
    "            #info(\"$(current_block) done\")\n",
    "        end\n",
    "        # carry out the best merges\n",
    "        \n",
    "        partition, num_blocks = carry_out_best_merges(\n",
    "                    delta_entropy_for_each_block, best_merge_for_each_block, partition, \n",
    "                    num_blocks, num_blocks_to_merge\n",
    "        )\n",
    "\n",
    "        # re-initialize edge counts and block degrees\n",
    "        interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees = initialize_edge_counts(\n",
    "                    g, num_blocks, partition)\n",
    "        \n",
    "        # perform nodal partition updates\n",
    "        println(\"Beginning nodal updates\")\n",
    "        total_num_nodal_moves = 0            \n",
    "        itr_delta_entropy = zeros(max_num_nodal_itr)\n",
    "\n",
    "        # compute the global entropy for MCMC convergence criterion\n",
    "        overall_entropy = compute_overall_entropy(\n",
    "                    interblock_edge_count, block_degrees_out, block_degrees_in, num_blocks, nv(g), ne(g)\n",
    "                )\n",
    "    \n",
    "        for itr in 1:max_num_nodal_itr\n",
    "            num_nodal_moves = 0\n",
    "            itr_delta_entropy[itr] = 0.0\n",
    "            println(\"$itr, $(num_nodal_moves)\")\n",
    "            for current_node in vertices(g)\n",
    "                current_block = partition[current_node] \n",
    "                # propose a new block for this node\n",
    "                # FIXME: weights are floats\n",
    "                out_blocks = out_neighbors(g, current_node)\n",
    "                out_blocks_counts = hcat(\n",
    "                    out_blocks, \n",
    "                    [round(Int64,get_weight(g, current_node, n)) for n in out_blocks]\n",
    "                )\n",
    "                in_blocks = in_neighbors(g, current_node)\n",
    "                in_blocks_counts = hcat(\n",
    "                    in_blocks, \n",
    "                    [round(Int64,get_weight(g, n, current_node)) for n in in_blocks]\n",
    "                )\n",
    "                #@show out_blocks, out_blocks_counts, in_blocks, in_blocks_counts\n",
    "                if (length(out_blocks) + length(in_blocks) == 0)\n",
    "                    #println(\"No neighbors found for $(current_block). Skipping.\")\n",
    "                    continue\n",
    "                end\n",
    "                proposal, num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges = propose_new_partition(\n",
    "                            current_block, out_blocks_counts, in_blocks_counts, partition, \n",
    "                            interblock_edge_count, block_degrees, num_blocks, false\n",
    "                        )\n",
    "                \n",
    "                # determine whether to accept or reject the proposal\n",
    "                if (proposal != current_block)\n",
    "                    # compute block counts of in and out neighbors\n",
    "                    out_blocks_count_map = countmap(\n",
    "                        partition[out_neighbors(g, current_node)], \n",
    "                        Distributions.weights([round(Int64, get_weight(g, current_node, n)) for n in out_neighbors(g, current_node)])\n",
    "                    )\n",
    "                    in_blocks_count_map = countmap(\n",
    "                        partition[in_neighbors(g, current_node)], \n",
    "                        Distributions.weights([round(Int64, get_weight(g, n, current_node)) for n in in_neighbors(g, current_node)])\n",
    "                    )\n",
    "                    \n",
    "                    out_blocks_counts = zeros(Int64, length(keys(out_blocks_count_map)), 2)\n",
    "                    in_blocks_counts = zeros(Int64, length(keys(in_blocks_count_map)), 2)\n",
    "                    \n",
    "                    for (idx, (block, count)) in enumerate(out_blocks_count_map)\n",
    "                        out_blocks_counts[idx, 1] = block\n",
    "                        out_blocks_counts[idx, 2] = count\n",
    "                    end\n",
    "                \n",
    "                    for (idx, (block, count)) in enumerate(in_blocks_count_map)\n",
    "                        in_blocks_counts[idx, 1] = block\n",
    "                        in_blocks_counts[idx, 2] = count\n",
    "                    end\n",
    "                    \n",
    "                    #@show out_blocks_counts, partition[out_neighbors(g, current_node)] \n",
    "                    #@show in_blocks_counts, partition[in_neighbors(g, current_node)]\n",
    "                    # compute the two new rows and columns of the interblock edge count matrix\n",
    "                    if has_edge(g, current_node, current_node)\n",
    "                        self_edge_weight = get_weight(g, current_node, current_node)\n",
    "                        println(\"self_edge_weight of $(self_edge_weight)\")\n",
    "                    else\n",
    "                        self_edge_weight = 0\n",
    "                    end\n",
    "                \n",
    "                    new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col = \n",
    "                        compute_new_rows_cols_interblock_edge_count_matrix(\n",
    "                        interblock_edge_count, current_block, proposal, \n",
    "                        out_blocks_counts[:, 1], out_blocks_counts[:, 2],\n",
    "                        in_blocks_counts[:, 1], in_blocks_counts[:, 2], \n",
    "                        self_edge_weight, false\n",
    "                    )\n",
    "                    #@show new_interblock_edge_count_current_block_row[in_blocks[:, 1]], \n",
    "                    #new_interblock_edge_count_current_block_col[out_blocks[:, 1]]\n",
    "                    @show find(x->x<0, new_interblock_edge_count_current_block_row)\n",
    "                    @show find(x->x<0, new_interblock_edge_count_new_block_row)\n",
    "                    @show find(x->x<0, new_interblock_edge_count_current_block_row)\n",
    "                    # compute new block degrees           \n",
    "                    block_degrees_out_new, block_degrees_in_new, block_degrees_new = compute_new_block_degrees(\n",
    "                        current_block, proposal, block_degrees_out, block_degrees_in, block_degrees, \n",
    "                        num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges\n",
    "                    )\n",
    "                  # compute the Hastings correction\n",
    "                    Hastings_correction = compute_Hastings_correction(\n",
    "                        out_blocks_counts[:, 1], out_blocks_counts[:, 2], in_blocks_counts[:, 1], in_blocks_counts[:, 2], \n",
    "                        proposal, interblock_edge_count, new_interblock_edge_count_current_block_row, \n",
    "                        new_interblock_edge_count_current_block_col, num_blocks, block_degrees, block_degrees_new\n",
    "                    )\n",
    "\n",
    "                    # compute change in entropy / posterior\n",
    "                    delta_entropy = compute_delta_entropy(current_block, proposal, interblock_edge_count,\n",
    "                    new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col,\n",
    "                    new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, \n",
    "                    block_degrees_out, block_degrees_in, block_degrees_out_new, block_degrees_in_new)\n",
    "                  end\n",
    "            end\n",
    "        end\n",
    "#=\n",
    "                    # compute probability of acceptance\n",
    "                    p_accept = min((e^(-β*delta_entropy))*Hastings_correction, 1)\n",
    "\n",
    "                    # if accept the proposal, update the partition, inter_block_edge_count, and block degrees\n",
    "                    if (rand() <= p_accept)\n",
    "                        total_num_nodal_moves += 1\n",
    "                        num_nodal_moves += 1\n",
    "                        itr_delta_entropy[itr] += delta_entropy\n",
    "                        println(\"Updating edge count for $(current_node) - $(current_block) to $(proposal)\")\n",
    "                        partition, interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees = update_partition(\n",
    "                            partition, current_node, current_block, proposal, interblock_edge_count,\n",
    "                            new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, \n",
    "                            new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col, \n",
    "                            block_degrees_out_new, block_degrees_in_new, block_degrees_new\n",
    "                        )\n",
    "                        for b_test in 1:num_blocks\n",
    "                            d = sum(interblock_edge_count[:, b_test] + interblock_edge_count[b_test, :])\n",
    "                            self_edge = interblock_edge_count[b_test, b_test]\n",
    "                            if (d != block_degrees_new[b_test] )\n",
    "                                println(\"$(b_test) inconsistent - $d, $(block_degrees_new[b_test]), $(self_edge)\")\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Itr: {}, number of nodal moves: {}, delta S: {:0.5f}\".format(itr, num_nodal_moves, itr_delta_entropy[itr]/float(overall_entropy)))\n",
    "            if itr>=(delta_entropy_moving_avg_window-1): # exit MCMC if the recent change in entropy falls below a small fraction of the overall entropy\n",
    "                if not(np.all(np.isfinite(old_overall_entropy))): # golden ratio bracket not yet established \n",
    "                    if (-np.mean(itr_delta_entropy[(itr-delta_entropy_moving_avg_window+1):itr]) < (delta_entropy_threshold1*overall_entropy)):\n",
    "                        break\n",
    "                else: # golden ratio bracket is established. Fine-tuning partition.\n",
    "                    if (-np.mean(itr_delta_entropy[(itr-delta_entropy_moving_avg_window+1):itr]) < (delta_entropy_threshold2*overall_entropy)):\n",
    "                        break\n",
    "                \n",
    "        # compute the global entropy for determining the optimal number of blocks\n",
    "        overall_entropy = compute_overall_entropy(interblock_edge_count, block_degrees_out, block_degrees_in, num_blocks, N, E, use_sparse_matrix)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Total number of nodal moves: {}, overall_entropy: {:0.2f}\".format(total_num_nodal_moves, overall_entropy))\n",
    "        if visualize_graph & use_graph_tool_options:\n",
    "            graph_object = plot_graph_with_partition(out_neighbors, partition, graph_object)\n",
    "\n",
    "        # check whether the partition with optimal number of block has been found; if not, determine and prepare for the next number of blocks to try\n",
    "        partition, interblock_edge_count, block_degrees, block_degrees_out, block_degrees_in, num_blocks, num_blocks_to_merge, old_partition, old_interblock_edge_count, old_block_degrees, old_block_degrees_out, old_block_degrees_in, old_overall_entropy, old_num_blocks, optimal_num_blocks_found = \\\n",
    "            prepare_for_partition_on_next_num_blocks(overall_entropy, partition, interblock_edge_count, block_degrees, block_degrees_out, block_degrees_in, num_blocks, old_partition, old_interblock_edge_count, old_block_degrees, old_block_degrees_out, old_block_degrees_in, old_overall_entropy, old_num_blocks, num_block_reduction_rate)\n",
    "\n",
    "        if verbose:\n",
    "            print('Overall entropy: {}'.format(old_overall_entropy))\n",
    "            print('Number of blocks: {}'.format(old_num_blocks))\n",
    "            if optimal_num_blocks_found:\n",
    "                print('\\nOptimal partition found with {} blocks'.format(num_blocks))\n",
    "    if use_timeit:\n",
    "        t1 = timeit.default_timer()\n",
    "        print('\\nGraph partition took {} seconds'.format(t1-t0))\n",
    "\n",
    "    # evaluate output partition against the true partition\n",
    "    evaluate_partition(true_partition, partition)\n",
    "\"\"\"\n",
    "=#\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36m{1000, 1978} directed simple Int64 graph with Float64 weightsLoaded\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging down blocks from 1000 to 500\n",
      "Beginning nodal updates\n",
      "1, 0\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "DomainError:\nlog will only return a complex result if called with a complex argument. Try log(complex(x)).",
     "output_type": "error",
     "traceback": [
      "DomainError:\nlog will only return a complex result if called with a complex argument. Try log(complex(x)).",
      "",
      "Stacktrace:",
      " [1] \u001b[1mnan_dom_err\u001b[22m\u001b[22m at \u001b[1m./math.jl:300\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1mlog\u001b[22m\u001b[22m at \u001b[1m./math.jl:419\u001b[22m\u001b[22m [inlined]",
      " [3] \u001b[1mcompute_delta_entropy\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Int64, ::Int64, ::Array{Int64,2}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Int64,1}, ::Array{Int64,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[25]:14\u001b[22m\u001b[22m",
      " [4] \u001b[1mmain\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[30]:216\u001b[22m\u001b[22m",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "main(\"emergingEdges\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "foo (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function foo()\n",
    "num_nodes = 1000\n",
    "g = SimpleWeightedDiGraph(1000)\n",
    "partition = collect(1:num_nodes)\n",
    "num_blocks = num_nodes\n",
    "load_graph!(g, \"emergingEdges\", 1000, 3)\n",
    "current_block = 1\n",
    "block_partition = collect(1:num_blocks)\n",
    "interblock_edge_count, block_degrees_out, block_degrees_in, block_degrees = \n",
    "        initialize_edge_counts(g, num_blocks, partition)\n",
    "                # populate edges to neighboring blocks\n",
    "                out_blocks = findn(interblock_edge_count[:, current_block])\n",
    "                out_blocks_counts = hcat(out_blocks, interblock_edge_count[out_blocks, current_block])\n",
    "                in_blocks = findn(interblock_edge_count[current_block, :])\n",
    "                in_blocks_counts = hcat(in_blocks, interblock_edge_count[current_block, in_blocks])\n",
    "\n",
    "                # propose a new block to merge with\n",
    "                proposal, num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges = \n",
    "                    propose_new_partition(\n",
    "                        current_block, out_blocks_counts, in_blocks_counts, block_partition, \n",
    "                        interblock_edge_count, block_degrees, num_blocks, true\n",
    "                    )\n",
    "                println(proposal)\n",
    "                new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row, new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col = \n",
    "                    compute_new_rows_cols_interblock_edge_count_matrix(\n",
    "                    interblock_edge_count, current_block, proposal, out_blocks_counts[:, 1], out_blocks_counts[:, 2],\n",
    "                    in_blocks_counts[:, 1], in_blocks_counts[:, 2], interblock_edge_count[current_block, current_block], \n",
    "                    true\n",
    "                )\n",
    "                @show findn.([new_interblock_edge_count_new_block_col, new_interblock_edge_count_new_block_row])\n",
    "              # compute new block degrees           \n",
    "                block_degrees_out_new, block_degrees_in_new, block_degrees_new = \n",
    "                    compute_new_block_degrees(\n",
    "                        current_block, proposal, block_degrees_out, block_degrees_in, block_degrees, \n",
    "                        num_out_neighbor_edges, num_in_neighbor_edges, num_neighbor_edges\n",
    "                )\n",
    "                delta_entropy = compute_delta_entropy(\n",
    "                    current_block, proposal, interblock_edge_count, \n",
    "                    new_interblock_edge_count_current_block_col, new_interblock_edge_count_new_block_col,\n",
    "                    new_interblock_edge_count_current_block_row, new_interblock_edge_count_new_block_row,\n",
    "                    block_degrees_out, block_degrees_in, block_degrees_out_new, block_degrees_in_new\n",
    "                )\n",
    "                \n",
    "                println(delta_entropy)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum.(([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@code_warntype main(\"emergingEdges\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
